{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address-Aware GNN for Cryptographic Function Detection\n",
    "\n",
    "This notebook provides an interactive interface for:\n",
    "1. Data exploration and visualization\n",
    "2. Model training and evaluation\n",
    "3. Inference on new binaries\n",
    "4. Analysis of address-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import our GNN modules\n",
    "from new_gnn import (\n",
    "    GraphDataset, AddressAwareGNN, HierarchicalGNN,\n",
    "    GNNTrainer, CryptoDetectionPipeline, collate_fn,\n",
    "    AddressFeatureExtractor\n",
    ")\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all JSON files\n",
    "data_dir = '/home/bhoomi/Desktop/compilerRepo/vestigo-data/ghidra_json'\n",
    "json_files = glob.glob(os.path.join(data_dir, '*.json'))\n",
    "\n",
    "print(f\"Found {len(json_files)} JSON files\")\n",
    "print(\"\\nSample files:\")\n",
    "for f in json_files[:5]:\n",
    "    print(f\"  - {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution\n",
    "all_labels = []\n",
    "all_addresses = []\n",
    "graph_complexities = []\n",
    "\n",
    "for json_file in tqdm(json_files[:100], desc=\"Analyzing data\"):\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for func in data['functions']:\n",
    "            if 'label' in func:\n",
    "                all_labels.append(func['label'])\n",
    "                all_addresses.append(func['address'])\n",
    "                graph_complexities.append(func.get('graph_level', {}).get('cyclomatic_complexity', 0))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Total functions analyzed: {len(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "label_counts = Counter(all_labels)\n",
    "labels, counts = zip(*label_counts.most_common())\n",
    "\n",
    "axes[0].barh(range(len(labels)), counts, color='steelblue')\n",
    "axes[0].set_yticks(range(len(labels)))\n",
    "axes[0].set_yticklabels(labels)\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_title('Label Distribution', fontweight='bold', fontsize=14)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Pie chart (top 10)\n",
    "top_10 = label_counts.most_common(10)\n",
    "labels_pie, counts_pie = zip(*top_10)\n",
    "axes[1].pie(counts_pie, labels=labels_pie, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Top 10 Label Distribution', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze complexity distribution by crypto type\n",
    "df = pd.DataFrame({\n",
    "    'label': all_labels,\n",
    "    'complexity': graph_complexities\n",
    "})\n",
    "\n",
    "# Filter to crypto functions only\n",
    "crypto_df = df[df['label'] != 'Non-Crypto']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=crypto_df, x='label', y='complexity', palette='Set2')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Crypto Algorithm', fontsize=12)\n",
    "plt.ylabel('Cyclomatic Complexity', fontsize=12)\n",
    "plt.title('Complexity Distribution by Crypto Algorithm', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('complexity_by_algorithm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComplexity statistics by algorithm:\")\n",
    "print(crypto_df.groupby('label')['complexity'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Address Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze address patterns\n",
    "sample_file = json_files[0]\n",
    "with open(sample_file, 'r') as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "# Extract address features for all functions\n",
    "address_features_list = []\n",
    "\n",
    "for func in sample_data['functions'][:50]:\n",
    "    for node in func.get('node_level', []):\n",
    "        addr_features = AddressFeatureExtractor.extract_address_features(node['address'])\n",
    "        addr_features['label'] = func.get('label', 'Unknown')\n",
    "        address_features_list.append(addr_features)\n",
    "\n",
    "addr_df = pd.DataFrame(address_features_list)\n",
    "print(\"Address features extracted:\", addr_df.shape)\n",
    "addr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize address features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = [\n",
    "    'addr_entropy',\n",
    "    'addr_alignment_4',\n",
    "    'addr_alignment_16',\n",
    "    'addr_ones_ratio',\n",
    "    'addr_nibble_variety',\n",
    "    'is_text_section'\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    crypto_only = addr_df[addr_df['label'] != 'Non-Crypto']\n",
    "    \n",
    "    axes[i].hist(crypto_only[feature], bins=30, alpha=0.6, label='Crypto', color='orange')\n",
    "    axes[i].hist(addr_df[addr_df['label'] == 'Non-Crypto'][feature], bins=30, alpha=0.6, label='Non-Crypto', color='blue')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'{feature} Distribution')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('address_features_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_files, test_files = train_test_split(json_files, test_size=0.15, random_state=42)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.15/0.85, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_files)} files\")\n",
    "print(f\"Val: {len(val_files)} files\")\n",
    "print(f\"Test: {len(test_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading training data...\")\n",
    "train_dataset = GraphDataset(train_files)\n",
    "\n",
    "print(\"\\nLoading validation data...\")\n",
    "val_dataset = GraphDataset(val_files, train_dataset.label_encoder)\n",
    "val_dataset.node_scaler = train_dataset.node_scaler\n",
    "val_dataset.edge_scaler = train_dataset.edge_scaler\n",
    "val_dataset.graph_scaler = train_dataset.graph_scaler\n",
    "\n",
    "print(\"\\nLoading test data...\")\n",
    "test_dataset = GraphDataset(test_files, train_dataset.label_encoder)\n",
    "test_dataset.node_scaler = train_dataset.node_scaler\n",
    "test_dataset.edge_scaler = train_dataset.edge_scaler\n",
    "test_dataset.graph_scaler = train_dataset.graph_scaler\n",
    "\n",
    "print(f\"\\nDatasets loaded successfully!\")\n",
    "print(f\"Classes: {train_dataset.label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "sample = train_dataset[0]\n",
    "num_node_features = sample.x.shape[1]\n",
    "num_edge_features = sample.edge_attr.shape[1] if sample.edge_attr.numel() > 0 else 0\n",
    "num_graph_features = sample.graph_features.shape[0]\n",
    "num_classes = len(train_dataset.label_encoder.classes_)\n",
    "\n",
    "print(f\"Node features: {num_node_features}\")\n",
    "print(f\"Edge features: {num_edge_features}\")\n",
    "print(f\"Graph features: {num_graph_features}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "model = AddressAwareGNN(\n",
    "    num_node_features=num_node_features,\n",
    "    num_edge_features=num_edge_features,\n",
    "    num_graph_features=num_graph_features,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=256,\n",
    "    num_layers=4,\n",
    "    dropout=0.3,\n",
    "    conv_type='gat',\n",
    "    pooling='concat'\n",
    ")\n",
    "\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = GNNTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    label_encoder=train_dataset.label_encoder,\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Train for specified epochs\n",
    "NUM_EPOCHS = 50\n",
    "trainer.train(num_epochs=NUM_EPOCHS, save_dir='./gnn_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "trainer.plot_training_history('./training_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('./gnn_models/best_model.pth', map_location=trainer.device)\n",
    "trainer.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "trainer.plot_confusion_matrix(test_results['confusion_matrix'], './confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-class performance\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_results['labels'],\n",
    "    test_results['predictions'],\n",
    "    labels=range(num_classes)\n",
    ")\n",
    "\n",
    "performance_df = pd.DataFrame({\n",
    "    'Class': train_dataset.label_encoder.classes_,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "}).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nPer-class performance:\")\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(performance_df))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, performance_df['Precision'], width, label='Precision', alpha=0.8)\n",
    "ax.bar(x, performance_df['Recall'], width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + width, performance_df['F1-Score'], width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Crypto Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Per-Class Performance Metrics', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(performance_df['Class'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata for inference\n",
    "metadata = {\n",
    "    'label_encoder': train_dataset.label_encoder,\n",
    "    'node_scaler': train_dataset.node_scaler,\n",
    "    'edge_scaler': train_dataset.edge_scaler,\n",
    "    'graph_scaler': train_dataset.graph_scaler,\n",
    "    'model_config': {\n",
    "        'num_node_features': num_node_features,\n",
    "        'num_edge_features': num_edge_features,\n",
    "        'num_graph_features': num_graph_features,\n",
    "        'num_classes': num_classes,\n",
    "        'hidden_dim': 256,\n",
    "        'num_layers': 4,\n",
    "        'dropout': 0.3,\n",
    "        'conv_type': 'gat',\n",
    "        'pooling': 'concat',\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('./gnn_models/metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"✓ Metadata saved for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a test file\n",
    "pipeline = CryptoDetectionPipeline(\n",
    "    model_path='./gnn_models/best_model.pth',\n",
    "    metadata_path='./gnn_models/metadata.pkl'\n",
    ")\n",
    "\n",
    "# Test on a sample file\n",
    "test_file = test_files[0]\n",
    "results = pipeline.process_json(test_file, './detection_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detection results\n",
    "if results['crypto_functions']:\n",
    "    # Algorithm distribution\n",
    "    algo_counts = Counter([f['algorithm'] for f in results['crypto_functions']])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    algos, counts = zip(*algo_counts.most_common())\n",
    "    axes[0].barh(range(len(algos)), counts, color='teal')\n",
    "    axes[0].set_yticks(range(len(algos)))\n",
    "    axes[0].set_yticklabels(algos)\n",
    "    axes[0].set_xlabel('Count')\n",
    "    axes[0].set_title('Detected Crypto Algorithms', fontweight='bold')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Confidence distribution\n",
    "    confidences = [f['confidence'] for f in results['crypto_functions']]\n",
    "    axes[1].hist(confidences, bins=20, color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('Confidence Score')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Detection Confidence Distribution', fontweight='bold')\n",
    "    axes[1].axvline(np.mean(confidences), color='red', linestyle='--', label=f'Mean: {np.mean(confidences):.3f}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('detection_results_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top detections\n",
    "    print(\"\\nTop 10 crypto functions by confidence:\")\n",
    "    for i, func in enumerate(results['crypto_functions'][:10], 1):\n",
    "        print(f\"{i}. {func['address']} - {func['algorithm']} (confidence: {func['confidence']:.4f})\")\n",
    "else:\n",
    "    print(\"No crypto functions detected in this file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which features are most important\n",
    "# We'll use gradient-based feature attribution\n",
    "\n",
    "def compute_feature_importance(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Compute feature importance using gradient magnitude.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    feature_gradients = []\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Computing importance\"):\n",
    "        batch = batch.to(device)\n",
    "        batch.x.requires_grad = True\n",
    "        \n",
    "        output = model(batch)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred = output.argmax(dim=1)\n",
    "        \n",
    "        # Compute gradient w.r.t. input features\n",
    "        loss = output[range(len(pred)), pred].sum()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Store gradient magnitudes\n",
    "        feature_gradients.append(batch.x.grad.abs().mean(dim=0).cpu().detach().numpy())\n",
    "    \n",
    "    # Average across batches\n",
    "    avg_importance = np.mean(feature_gradients, axis=0)\n",
    "    \n",
    "    return avg_importance\n",
    "\n",
    "# Compute feature importance\n",
    "importance = compute_feature_importance(trainer.model, val_loader, trainer.device)\n",
    "\n",
    "# Visualize top features\n",
    "top_k = 30\n",
    "top_indices = np.argsort(importance)[-top_k:][::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(top_k), importance[top_indices], color='purple', alpha=0.7)\n",
    "plt.yticks(range(top_k), [f'Feature {i}' for i in top_indices])\n",
    "plt.xlabel('Importance (Gradient Magnitude)', fontsize=12)\n",
    "plt.ylabel('Feature Index', fontsize=12)\n",
    "plt.title(f'Top {top_k} Most Important Node Features', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop {top_k} feature indices: {top_indices.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple architectures and compare\n",
    "architectures = ['gcn', 'gat', 'sage', 'gin']\n",
    "results_comparison = []\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {arch.upper()} model\")\n",
    "    print('='*60)\n",
    "    \n",
    "    model = AddressAwareGNN(\n",
    "        num_node_features=num_node_features,\n",
    "        num_edge_features=num_edge_features,\n",
    "        num_graph_features=num_graph_features,\n",
    "        num_classes=num_classes,\n",
    "        hidden_dim=256,\n",
    "        num_layers=4,\n",
    "        dropout=0.3,\n",
    "        conv_type=arch,\n",
    "        pooling='concat'\n",
    "    )\n",
    "    \n",
    "    trainer = GNNTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        label_encoder=train_dataset.label_encoder,\n",
    "        lr=0.001,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    \n",
    "    # Train for fewer epochs for comparison\n",
    "    trainer.train(num_epochs=30, save_dir=f'./gnn_models/{arch}')\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc, test_f1, _, _ = trainer.evaluate(test_loader)\n",
    "    \n",
    "    results_comparison.append({\n",
    "        'architecture': arch.upper(),\n",
    "        'test_acc': test_acc,\n",
    "        'test_f1': test_f1,\n",
    "        'test_loss': test_loss\n",
    "    })\n",
    "\n",
    "# Compare results\n",
    "comparison_df = pd.DataFrame(results_comparison)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ARCHITECTURE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize architecture comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "# Accuracy\n",
    "axes[0].bar(x, comparison_df['test_acc'], width, label='Accuracy', color='skyblue')\n",
    "axes[0].set_xlabel('Architecture', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Test Accuracy by Architecture', fontweight='bold', fontsize=14)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(comparison_df['architecture'])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1].bar(x, comparison_df['test_f1'], width, label='F1 Score', color='coral')\n",
    "axes[1].set_xlabel('Architecture', fontsize=12)\n",
    "axes[1].set_ylabel('F1 Score', fontsize=12)\n",
    "axes[1].set_title('Test F1 Score by Architecture', fontweight='bold', fontsize=14)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(comparison_df['architecture'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('architecture_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✓ Data exploration and label distribution analysis\n",
    "2. ✓ Address-based feature extraction and visualization\n",
    "3. ✓ GNN model training with comprehensive metrics\n",
    "4. ✓ Model evaluation and confusion matrix analysis\n",
    "5. ✓ Inference pipeline for crypto detection\n",
    "6. ✓ Feature importance analysis\n",
    "7. ✓ Architecture comparison (GCN, GAT, SAGE, GIN)\n",
    "\n",
    "**Next steps:**\n",
    "- Run hyperparameter tuning with `gnn_hyperparameter_tuning.py`\n",
    "- Deploy model for production inference\n",
    "- Analyze false positives/negatives for model improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
